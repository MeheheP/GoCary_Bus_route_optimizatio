{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e574331-7012-4e7d-ad38-3950f3e7ea5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What would you like to do?\n",
      "1. Collect Data Only (runs until you stop it)\n",
      "2. Analyze Existing Data Only\n",
      "3. Collect Data for a specific time, then Analyze\n",
      "4. Visualize Analysis Results\n",
      "5. Generate Layered Interactive Map\n",
      "6. Train and Evaluate ML Model (Random Forest)\n",
      "7. Train and Evaluate ML Model (LightGBM)\n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# Imports & Config\n",
    "# ===========================\n",
    "import requests\n",
    "from google.transit import gtfs_realtime_pb2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import folium\n",
    "import joblib\n",
    "try:\n",
    "    import geopandas as gpd\n",
    "    from shapely.geometry import Point\n",
    "    GEOPANDAS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    GEOPANDAS_AVAILABLE = False\n",
    "\n",
    "# ---- Main configuration ----\n",
    "DATADIRECTORY =  r\"C:\\Users\\hp\\OneDrive\\Desktop\\DesktopFolders\\data\"\n",
    "GOCARYVEHICLEPOSITIONSURL = \"https://www.gocarylive.org/GTFSRealtime/GTFSVehiclePositions.pb\"\n",
    "GOCARYTRIPUPDATESURL = \"https://www.gocarylive.org/GTFSRealtime/GTFSTripUpdates.pb\"\n",
    "GOTRIANGLEVEHICLEPOSITIONSURL = \"https://gotriangle.tripsparkhost.com/gtfsRealtime/GTFSVehiclePositions.pb\"\n",
    "POPULATIONGEOJSONFILE = \"CensusBlockGroups2020.geojson\"\n",
    "\n",
    "def log(msg: str):\n",
    "    print(f\"[INFO] {datetime.now():%Y-%m-%d %H:%M:%S} - {msg}\")\n",
    "\n",
    "# ===========================\n",
    "# Utility & Data Functions\n",
    "# ===========================\n",
    "def fetchgtfsrealtimedata(url: str):\n",
    "    \"\"\"Fetches and parses a GTFS-RT feed from a given URL.\"\"\"\n",
    "    feed = gtfs_realtime_pb2.FeedMessage()\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=15)\n",
    "        if response.status_code == 200:\n",
    "            feed.ParseFromString(response.content)\n",
    "            return feed\n",
    "        else:\n",
    "            log(f\"Error fetching {url} - Status {response.status_code}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        log(f\"An error occurred fetching {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def parsevehiclepositions(feed):\n",
    "    \"\"\"Parses vehicle position data from a feed message.\"\"\"\n",
    "    busdata = {}\n",
    "    if not feed: return busdata\n",
    "    for entity in feed.entity:\n",
    "        if entity.HasField('vehicle') and entity.vehicle.trip.trip_id:\n",
    "            tripid = entity.vehicle.trip.trip_id\n",
    "            busdata[tripid] = {\n",
    "                \"vehicleid\": entity.vehicle.vehicle.id,\n",
    "                \"latitude\": entity.vehicle.position.latitude,\n",
    "                \"longitude\": entity.vehicle.position.longitude\n",
    "            }\n",
    "    return busdata\n",
    "\n",
    "def parsetripupdates(feed):\n",
    "    \"\"\"Parses trip update data delays from a feed message.\"\"\"\n",
    "    tripupdates = {}\n",
    "    if not feed: return tripupdates\n",
    "    for entity in feed.entity:\n",
    "        if entity.HasField('trip_update') and entity.trip_update.trip.trip_id:\n",
    "            tripid = entity.trip_update.trip.trip_id\n",
    "            for stopupdate in entity.trip_update.stop_time_update:\n",
    "                if stopupdate.HasField('arrival') and stopupdate.arrival.HasField('delay'):\n",
    "                    tripupdates[tripid] = stopupdate.arrival.delay / 60.0\n",
    "                    break\n",
    "    return tripupdates\n",
    "\n",
    "def savedatatocsv(data, filepath):\n",
    "    df = pd.DataFrame(data)\n",
    "    if not os.path.isfile(filepath):\n",
    "        df.to_csv(filepath, index=False)\n",
    "    else:\n",
    "        df.to_csv(filepath, mode='a', header=False, index=False)\n",
    "\n",
    "def rundatacollection(datadirectory, durationminutes=None):\n",
    "    starttime = time.time()\n",
    "    gocarycsv = os.path.join(datadirectory, \"gocarydata.csv\")\n",
    "    gotrianglecsv = os.path.join(datadirectory, \"gotriangledata.csv\")\n",
    "    log(f\"Starting data collection. Data will be saved in {datadirectory}\")\n",
    "    if durationminutes:\n",
    "        log(f\"This will run for {durationminutes} minutes.\")\n",
    "    else:\n",
    "        log(\"Press Ctrl+C to stop.\")\n",
    "    while True:\n",
    "        if durationminutes and (time.time() - starttime > durationminutes * 60):\n",
    "            log(\"Specified duration reached. Stopping data collection.\")\n",
    "            break\n",
    "        try:\n",
    "            gcpositions = parsevehiclepositions(fetchgtfsrealtimedata(GOCARYVEHICLEPOSITIONSURL))\n",
    "            gcupdates = parsetripupdates(fetchgtfsrealtimedata(GOCARYTRIPUPDATESURL))\n",
    "            combinedgocarydata = []\n",
    "            for tripid, posdata in gcpositions.items():\n",
    "                record = {\n",
    "                    \"timestamp\": datetime.now().isoformat(),\n",
    "                    \"tripid\": tripid,\n",
    "                    **posdata,\n",
    "                    \"delayminutes\": gcupdates.get(tripid)\n",
    "                }\n",
    "                combinedgocarydata.append(record)\n",
    "            if combinedgocarydata:\n",
    "                savedatatocsv(combinedgocarydata, gocarycsv)\n",
    "                log(f\"Saved {len(combinedgocarydata)} GoCary records.\")\n",
    "            gtpositions = parsevehiclepositions(fetchgtfsrealtimedata(GOTRIANGLEVEHICLEPOSITIONSURL))\n",
    "            combinedgotriangledata = []\n",
    "            for tripid, posdata in gtpositions.items():\n",
    "                record = {\n",
    "                    \"timestamp\": datetime.now().isoformat(),\n",
    "                    \"tripid\": tripid,\n",
    "                    **posdata,\n",
    "                    \"delayminutes\": None\n",
    "                }\n",
    "                combinedgotriangledata.append(record)\n",
    "            if combinedgotriangledata:\n",
    "                savedatatocsv(combinedgotriangledata, gotrianglecsv)\n",
    "                log(f\"Saved {len(combinedgotriangledata)} GoTriangle records.\")\n",
    "            time.sleep(30)\n",
    "        except KeyboardInterrupt:\n",
    "            log(\"Data collection stopped by user.\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            log(f\"Unexpected error: {e}\")\n",
    "            time.sleep(30)\n",
    "\n",
    "# ===========================\n",
    "# Data Analysis\n",
    "# ===========================\n",
    "def analyzeontimeperformance(datadirectory):\n",
    "    log(\"--- Starting On-Time Performance Analysis ---\")\n",
    "    realtimecsv = os.path.join(datadirectory, \"gocarydata.csv\")\n",
    "    staticfolder = os.path.join(datadirectory, \"gtfsstatic\")\n",
    "    outputcsv = os.path.join(datadirectory, \"gocaryanalysis.csv\")\n",
    "    if not os.path.exists(realtimecsv) or not os.path.isdir(staticfolder):\n",
    "        log(\"Error: Missing required files in datadirectory. Ensure gocarydata.csv and gtfsstatic folder exist.\")\n",
    "        return\n",
    "    try:\n",
    "        realtimedf = pd.read_csv(realtimecsv)\n",
    "        realtimedf.dropna(subset=[\"delayminutes\"], inplace=True)\n",
    "        realtimedf[\"tripid\"] = realtimedf[\"tripid\"].astype(str)\n",
    "        routesdf = pd.read_csv(os.path.join(staticfolder, \"routes.txt\"))\n",
    "        tripsdf = pd.read_csv(os.path.join(staticfolder, \"trips.txt\"))\n",
    "        tripsdf[\"tripid\"] = tripsdf[\"tripid\"].astype(str)\n",
    "        tripswithroutes = pd.merge(tripsdf, routesdf, on=\"routeid\")\n",
    "        analysisdf = pd.merge(realtimedf, tripswithroutes[[\"tripid\", \"routeshortname\"]], on=\"tripid\", how=\"left\")\n",
    "        finalcolumns = [\"timestamp\", \"routeshortname\", \"vehicleid\", \"latitude\", \"longitude\", \"delayminutes\", \"tripid\"]\n",
    "        finaldf = analysisdf[[col for col in finalcolumns if col in analysisdf.columns]]\n",
    "        finaldf.to_csv(outputcsv, index=False)\n",
    "        log(f\"--- Analysis complete! Results saved to {outputcsv} ---\")\n",
    "        log(\"--- Sample of Final Analysis Data ---\")\n",
    "        log(finaldf.head())\n",
    "    except Exception as e:\n",
    "        log(f\"Error loading data files: {e}\")\n",
    "\n",
    "# ===========================\n",
    "# Visualization\n",
    "# ===========================\n",
    "def visualizedata():\n",
    "    log(\"--- Starting Data Visualization ---\")\n",
    "    analysisfile = os.path.join(DATADIRECTORY, \"gocaryanalysis.csv\")\n",
    "    if not os.path.exists(analysisfile):\n",
    "        log(f\"Error: Analysis file not found at {analysisfile}. Run analyze mode first.\")\n",
    "        return\n",
    "    try:\n",
    "        df = pd.read_csv(analysisfile)\n",
    "        if df.empty:\n",
    "            log(\"Warning: The analysis file is empty. No data to visualize.\")\n",
    "            return\n",
    "        df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "        log(\"--- Key Performance Statistics ---\")\n",
    "        avgdelay = df[\"delayminutes\"].mean()\n",
    "        log(f\"Average Delay: {avgdelay:.2f} minutes\")\n",
    "        ontimethresholdupper, ontimethresholdlower = 5, -2\n",
    "        ontime = df[(df[\"delayminutes\"] >= ontimethresholdlower) & (df[\"delayminutes\"] <= ontimethresholdupper)]\n",
    "        log(f\"On-Time Percentage: {len(ontime) / len(df) * 100:.1f}%\")\n",
    "        late = df[df[\"delayminutes\"] > ontimethresholdupper]\n",
    "        log(f\"Late Percentage: {len(late) / len(df) * 100:.1f}%\")\n",
    "        early = df[df[\"delayminutes\"] < ontimethresholdlower]\n",
    "        log(f\"Early Percentage: {len(early) / len(df) * 100:.1f}%\")\n",
    "        sns.set_style(\"whitegrid\")\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.histplot(df[\"delayminutes\"], bins=30, kde=True)\n",
    "        plt.title(\"Distribution of GoCary Bus Delays\", fontsize=16)\n",
    "        plt.xlabel(\"Delay Minutes\"); plt.ylabel(\"Number of Observations\")\n",
    "        plt.xlim(-15, 20)\n",
    "        plt.axvline(x=0, color=\"black\", linestyle=\"--\"); plt.text(0.5, plt.ylim()[1]*0.9, \"On-Time\", color=\"black\")\n",
    "        distpath = os.path.join(DATADIRECTORY, \"delaydistribution.png\")\n",
    "        plt.savefig(distpath); plt.close()\n",
    "        log(f\"Saved delay distribution plot to {distpath}\")\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        order = df.groupby(\"routeshortname\")[\"delayminutes\"].median().sort_values().index\n",
    "        sns.boxplot(x=\"routeshortname\", y=\"delayminutes\", data=df, order=order)\n",
    "        plt.xticks(rotation=45); plt.tight_layout()\n",
    "        routepath = os.path.join(DATADIRECTORY, \"delaybyroute.png\")\n",
    "        plt.savefig(routepath); plt.close()\n",
    "        log(f\"Saved delay by route plot to {routepath}\")\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        df.set_index(\"timestamp\", inplace=True)\n",
    "        hourlydelay = df[\"delayminutes\"].resample(\"H\").mean()\n",
    "        hourlydelay.plot(marker=\"o\")\n",
    "        plt.title(\"Average Delay by Hour of Day\")\n",
    "        plt.axhline(y=0, color=\"black\", linestyle=\"--\")\n",
    "        timepath = os.path.join(DATADIRECTORY, \"delayovertime.png\")\n",
    "        plt.savefig(timepath)\n",
    "        plt.close()\n",
    "        log(f\"Saved delay over time plot to {timepath}\")\n",
    "    except Exception as e:\n",
    "        log(f\"Unexpected error during visualization: {e}\")\n",
    "\n",
    "# ===========================\n",
    "# Map Generation\n",
    "# ===========================\n",
    "def plotlayeredmap():\n",
    "    log(\"--- Starting Layered Map Generation ---\")\n",
    "    staticfolder = os.path.join(DATADIRECTORY, \"gtfsstatic\")\n",
    "    shapesfile = os.path.join(staticfolder, \"shapes.txt\")\n",
    "    routesfile = os.path.join(staticfolder, \"routes.txt\")\n",
    "    tripsfile = os.path.join(staticfolder, \"trips.txt\")\n",
    "    stopsfile = os.path.join(staticfolder, \"stops.txt\")\n",
    "    populationfile = os.path.join(DATADIRECTORY, POPULATIONGEOJSONFILE)\n",
    "    outputmapfile = os.path.join(DATADIRECTORY, \"gocarylayeredmap.html\")\n",
    "    if not all(map(os.path.exists, [shapesfile, routesfile, tripsfile, stopsfile])):\n",
    "        log(\"Error: Required GTFS file(s) not found.\")\n",
    "        return\n",
    "    try:\n",
    "        log(\"Loading GTFS schedule data...\")\n",
    "        shapesdf = pd.read_csv(shapesfile)\n",
    "        tripsdf = pd.read_csv(tripsfile)\n",
    "        routesdf = pd.read_csv(routesfile)\n",
    "        stopsdf = pd.read_csv(stopsfile)\n",
    "        m = folium.Map(location=[35.7915, -78.7811], zoom_start=12, tiles=\"CartoDB positron\")\n",
    "        if GEOPANDAS_AVAILABLE and os.path.exists(populationfile):\n",
    "            log(\"Processing population data for choropleth layer...\")\n",
    "            populationgdf = gpd.read_file(populationfile)\n",
    "            if populationgdf.crs != \"EPSG:4326\":\n",
    "                populationgdf = populationgdf.to_crs(\"EPSG:4326\")\n",
    "            folium.Choropleth(\n",
    "                geo_data=populationgdf,\n",
    "                name=\"Population Density\",\n",
    "                data=populationgdf,\n",
    "                columns=[\"GEOID\", \"POPULATION\"],\n",
    "                key_on=\"feature.properties.GEOID\",\n",
    "                fill_color=\"YlGn\",\n",
    "                fill_opacity=0.6,\n",
    "                line_opacity=0.2,\n",
    "                legend_name=\"Population per Census Block Group (2020)\",\n",
    "                show=False\n",
    "            ).add_to(m)\n",
    "        else:\n",
    "            log(\"Population data or geopandas not available. Choropleth skipped.\")\n",
    "        log(\"Processing individual bus route layers...\")\n",
    "        tripswithroutes = pd.merge(tripsdf, routesdf, on=\"routeid\")\n",
    "        shapetoroute = tripswithroutes.drop_duplicates(\"shapeid\")\n",
    "        shapesinfo = pd.merge(shapesdf, shapetoroute[[\"shapeid\", \"routeshortname\", \"routelongname\", \"routecolor\"]], on=\"shapeid\")\n",
    "        for routename, group in shapesinfo.groupby(\"routeshortname\"):\n",
    "            layer = folium.FeatureGroup(name=f\"Route {routename}\", show=False)\n",
    "            for shapeid, seg in group.groupby(\"shapeid\"):\n",
    "                seg = seg.sort_values(\"shape_pt_sequence\")\n",
    "                linepoints = list(zip(seg[\"shape_pt_lat\"], seg[\"shape_pt_lon\"]))\n",
    "                color = f\"#{seg.iloc[0]['routecolor']}\" if pd.notnull(seg.iloc[0]['routecolor']) else \"#000000\"\n",
    "                folium.PolyLine(\n",
    "                    locations=linepoints,\n",
    "                    color=color,\n",
    "                    weight=4, opacity=0.9,\n",
    "                    popup=f\"<b>Route {routename}</b>\"\n",
    "                ).add_to(layer)\n",
    "            layer.add_to(m)\n",
    "        stopslayer = folium.FeatureGroup(name=\"All Bus Stops\", show=True)\n",
    "        for _, stop in stopsdf.iterrows():\n",
    "            folium.CircleMarker(\n",
    "                location=[stop[\"stop_lat\"], stop[\"stop_lon\"]],\n",
    "                radius=2, color=\"#555555\", weight=1,\n",
    "                popup=f\"<b>Stop:</b> {stop['stop_name']}\",\n",
    "            ).add_to(stopslayer)\n",
    "        stopslayer.add_to(m)\n",
    "        proposedroutelayer = folium.FeatureGroup(name=\"PROPOSED West Cary Connector\", show=True)\n",
    "        # Example stops for new route (replace with your data as needed)\n",
    "        proposedstops = [\n",
    "            {\"name\": \"Parkside Town Commons\", \"lat\": 35.820, \"lon\": -78.852},\n",
    "            {\"name\": \"Green Level West at Mills Park Dr\", \"lat\": 35.815, \"lon\": -78.850},\n",
    "            {\"name\": \"Green Level West at Carpenter Fire Station Rd\", \"lat\": 35.805, \"lon\": -78.845}\n",
    "        ]\n",
    "        linecoords = [(stop[\"lat\"], stop[\"lon\"]) for stop in proposedstops]\n",
    "        folium.PolyLine(\n",
    "            locations=linecoords, color=\"crimson\", weight=5, opacity=0.8, dash_array=\"10,5\",\n",
    "            popup=\"Proposed Route 9 West Cary Connector\"\n",
    "        ).add_to(proposedroutelayer)\n",
    "        for stop in proposedstops:\n",
    "            folium.Marker(\n",
    "                location=[stop[\"lat\"], stop[\"lon\"]],\n",
    "                popup=f\"<b>Proposed Stop:</b> {stop['name']}\",\n",
    "                icon=folium.Icon(color=\"green\", icon=\"plus\")\n",
    "            ).add_to(proposedroutelayer)\n",
    "        proposedroutelayer.add_to(m)\n",
    "        folium.LayerControl().add_to(m)\n",
    "        m.save(outputmapfile)\n",
    "        log(f\"--- Success! Interactive layered map saved to {outputmapfile} ---\")\n",
    "    except Exception as e:\n",
    "        log(f\"Error generating map: {e}\")\n",
    "\n",
    "# ===========================\n",
    "# ML Models\n",
    "# ===========================\n",
    "def trainandevaluatemodel():\n",
    "    log(\"--- Starting Machine Learning Model Training ---\")\n",
    "    analysisfile = os.path.join(DATADIRECTORY, \"gocaryanalysis.csv\")\n",
    "    modeloutputfile = os.path.join(DATADIRECTORY, \"busdelaymodel.joblib\")\n",
    "    if not os.path.exists(analysisfile):\n",
    "        log(f\"Error: Analysis file not found at {analysisfile}. Run analysis first.\")\n",
    "        return\n",
    "    try:\n",
    "        df = pd.read_csv(analysisfile).dropna(subset=[\"delayminutes\", \"routeshortname\"])\n",
    "        if df.empty:\n",
    "            log(\"Error: No data after cleaning.\")\n",
    "            return\n",
    "        df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "        df[\"hour\"] = df[\"timestamp\"].dt.hour\n",
    "        df[\"dayofweek\"] = df[\"timestamp\"].dt.dayofweek\n",
    "        df = pd.get_dummies(df, columns=[\"routeshortname\"], prefix=\"route\")\n",
    "        y = df[\"delayminutes\"]\n",
    "        featurecols = [\"latitude\", \"longitude\", \"hour\", \"dayofweek\"] + [col for col in df.columns if col.startswith(\"route\")]\n",
    "        X = df[featurecols]\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "        from sklearn.metrics import mean_absolute_error\n",
    "        Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1, min_samples_leaf=5)\n",
    "        model.fit(Xtrain, ytrain)\n",
    "        predictions = model.predict(Xtest)\n",
    "        mae = mean_absolute_error(ytest, predictions)\n",
    "        log(f\"Model Mean Absolute Error (MAE): {mae:.2f} minutes\")\n",
    "        joblib.dump(model, modeloutputfile)\n",
    "        log(f\"Model saved to {modeloutputfile}\")\n",
    "        # Example prediction\n",
    "        sample = Xtest.iloc[0].copy()\n",
    "        for col in sample.index:\n",
    "            if \"route\" in col: sample[col] = 0\n",
    "        if \"route_6\" in sample.index:\n",
    "            sample[\"route_6\"] = 1  # e.g., Route 6\n",
    "        sample[\"hour\"] = 15; sample[\"dayofweek\"] = 1\n",
    "        sampledf = pd.DataFrame([sample])\n",
    "        pred = model.predict(sampledf)[0]\n",
    "        log(f\"Sample Prediction (Route 6, Tue 3 PM): {pred:.2f} minutes {'EARLY' if pred < -2 else 'LATE' if pred > 5 else 'ON TIME'}\")\n",
    "    except Exception as e:\n",
    "        log(f\"Error during ML model training: {e}\")\n",
    "\n",
    "def trainlightgbmmodel():\n",
    "    log(\"--- Starting LightGBM Model Training ---\")\n",
    "    analysisfile = os.path.join(DATADIRECTORY, \"gocaryanalysis.csv\")\n",
    "    modeloutputfile = os.path.join(DATADIRECTORY, \"busdelaylightgbmmodel.joblib\")\n",
    "    if not os.path.exists(analysisfile):\n",
    "        log(f\"Error: Analysis file not found at {analysisfile}. Run analysis first.\")\n",
    "        return\n",
    "    try:\n",
    "        import lightgbm as lgb\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        from sklearn.metrics import mean_absolute_error, r2_score\n",
    "        df = pd.read_csv(analysisfile).dropna(subset=[\"delayminutes\", \"routeshortname\"])\n",
    "        df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "        df[\"hour\"] = df[\"timestamp\"].dt.hour\n",
    "        df[\"minute\"] = df[\"timestamp\"].dt.minute\n",
    "        df[\"dayofweek\"] = df[\"timestamp\"].dt.dayofweek\n",
    "        df[\"timeofday_numeric\"] = df[\"hour\"] + df[\"minute\"] / 60.0\n",
    "        df[\"routeshortname\"] = df[\"routeshortname\"].astype(\"category\")\n",
    "        y = df[\"delayminutes\"]\n",
    "        X = df[[\"latitude\", \"longitude\", \"timeofday_numeric\", \"dayofweek\", \"routeshortname\"]]\n",
    "        Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        lgbm = lgb.LGBMRegressor(random_state=42)\n",
    "        lgbm.fit(Xtrain, ytrain, categorical_feature=['routeshortname'])\n",
    "        predictions = lgbm.predict(Xtest)\n",
    "        mae = mean_absolute_error(ytest, predictions)\n",
    "        r2 = r2_score(ytest, predictions)\n",
    "        log(f\"LightGBM MAE: {mae:.2f} min, R-squared: {r2:.2f}\")\n",
    "        joblib.dump(lgbm, modeloutputfile)\n",
    "        log(f\"LightGBM model saved to {modeloutputfile}\")\n",
    "    except Exception as e:\n",
    "        log(f\"Error during LightGBM training: {e}\")\n",
    "\n",
    "# ===========================\n",
    "# Main Block & Menu\n",
    "# ===========================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"What would you like to do?\")\n",
    "    print(\"1. Collect Data Only (runs until you stop it)\")\n",
    "    print(\"2. Analyze Existing Data Only\")\n",
    "    print(\"3. Collect Data for a specific time, then Analyze\")\n",
    "    print(\"4. Visualize Analysis Results\")\n",
    "    print(\"5. Generate Layered Interactive Map\")\n",
    "    print(\"6. Train and Evaluate ML Model (Random Forest)\")\n",
    "    print(\"7. Train and Evaluate ML Model (LightGBM)\")\n",
    "    choice = input(\"Enter your choice (1-7): \")\n",
    "    if choice == \"1\":\n",
    "        rundatacollection(DATADIRECTORY)\n",
    "    elif choice == \"2\":\n",
    "        analyzeontimeperformance(DATADIRECTORY)\n",
    "    elif choice == \"3\":\n",
    "        try:\n",
    "            duration = int(input(\"How many minutes do you want to collect data for? \"))\n",
    "            rundatacollection(DATADIRECTORY, durationminutes=duration)\n",
    "            analyzeontimeperformance(DATADIRECTORY)\n",
    "        except ValueError:\n",
    "            log(\"Invalid input: Please enter a number.\")\n",
    "    elif choice == \"4\":\n",
    "        visualizedata()\n",
    "    elif choice == \"5\":\n",
    "        plotlayeredmap()\n",
    "    elif choice == \"6\":\n",
    "        trainandevaluatemodel()\n",
    "    elif choice == \"7\":\n",
    "        trainlightgbmmodel()\n",
    "    else:\n",
    "        print(\"Invalid choice. Please enter a number between 1 and 7.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5077fea3-ccd9-4cc7-a6b2-3489c0b1d698",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
